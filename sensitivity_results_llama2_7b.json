{
  "model": {
    "name": "meta-llama/Llama-2-7b-hf",
    "num_layers": 32,
    "hidden_size": 4096,
    "num_attention_heads": 32
  },
  "dataset": {
    "name": "wikitext",
    "config": "wikitext-2-raw-v1",
    "num_samples": 64
  },
  "method": "fisher",
  "sensitivity_scores": [
    69.49548786599189,
    313.9089561160654,
    1.666753627359867,
    2.0320918476209044,
    3.1417012978345156,
    2.158781934529543,
    3.2820508731529117,
    2.5833608098328114,
    3.3863691687583923,
    2.273673134855926,
    1.4299229132011533,
    3.1318548563867807,
    1.2574267899617553,
    1.8788405628874898,
    1.532290268689394,
    1.6198238218203187,
    2.2806727634742856,
    1.6564147789031267,
    12.356253524310887,
    1.6564769940450788,
    1.0849082181230187,
    1.1185915768146515,
    1.1100375168025494,
    1.0778065966442227,
    1.1750693190842867,
    1.4914252813905478,
    1.949669319204986,
    2.407552652992308,
    2.490719549357891,
    4.222238224931061,
    71.89082150347531,
    20.806122635491192
  ],
  "ranked_layers": [
    1,
    30,
    0,
    31,
    18,
    29,
    8,
    6,
    4,
    11,
    7,
    28,
    27,
    16,
    9,
    5,
    3,
    26,
    13,
    2,
    19,
    17,
    15,
    14,
    25,
    10,
    12,
    24,
    21,
    22,
    20,
    23
  ],
  "statistics": {
    "mean": 16.986067698249826,
    "std": 55.907197489684414,
    "min": 1.0778065966442227,
    "max": 313.9089561160654,
    "most_sensitive_layer": 1,
    "least_sensitive_layer": 23
  },
  "gpu_info": {
    "name": "NVIDIA A100-SXM4-40GB",
    "memory_allocated_gb": 26.970702336,
    "memory_reserved_gb": 28.338814976
  }
}